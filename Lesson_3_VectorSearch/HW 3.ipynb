{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678754d5-05cb-4c94-8c3f-a0120f8da025",
   "metadata": {},
   "source": [
    "## Homework: Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c005373-8fc1-4bf0-a7c2-435a96a8c069",
   "metadata": {},
   "source": [
    "## Q1. Getting the embeddings model\n",
    "\n",
    "First, we will get the embeddings model `multi-qa-distilbert-cos-v1` from\n",
    "[the Sentence Transformer library](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#model-overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0a8f8-ca06-48b2-9a5e-2e5ac17496b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers==2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16b0a6a8-cefd-4cd7-a6c2-25af7ec04801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sentence-transformers\n",
      "Version: 2.7.0\n",
      "Summary: Multilingual text embeddings\n",
      "Home-page: https://www.SBERT.net\n",
      "Author: Nils Reimers\n",
      "Author-email: info@nils-reimers.de\n",
      "License: Apache License 2.0\n",
      "Location: /usr/local/python/3.10.13/lib/python3.10/site-packages\n",
      "Requires: huggingface-hub, numpy, Pillow, scikit-learn, scipy, torch, tqdm, transformers\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a40b675e-d48d-4e14-80cd-d51afc9d9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer('multi-qa-distilbert-cos-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4aad01-2b75-4457-b6a6-c2e9ce0d2c55",
   "metadata": {},
   "source": [
    "Create the embedding for this user question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd076936-b7c4-4d34-85a5-bec9f2d9ee49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer #1: 0.07822265475988388\n"
     ]
    }
   ],
   "source": [
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "encoded = embedding_model.encode(user_question)\n",
    "print(f\"Answer #1: {encoded[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fe31f0e-8dec-4e10-beca-d982af6dcb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92428f06-4bfb-4661-96bd-3e70dfb4fe44",
   "metadata": {},
   "source": [
    "## Prepare the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7fb40-892e-4d6c-9c96-f7b0079c2799",
   "metadata": {},
   "source": [
    "Now we will create the embeddings for the documents.\n",
    "\n",
    "Load the documents with ids that we prepared in the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00211dfb-2434-4dda-84c9-ed5ee03b4f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61770c67-00ee-4b35-95c9-3b481e02319d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - What are the prerequisites for this course?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': '1f6520ca'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81946998-cf85-4704-b476-ec14be076e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All documents\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c8ebf6c-916f-4f15-8e83-61611d5136c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only 'machine-learning-zoomcamp' documents\n",
    "docs_mlzc = [doc for doc in documents if doc['course'] == 'machine-learning-zoomcamp']\n",
    "len(docs_mlzc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b68109-23e3-4f6c-a30c-6a8c412e2206",
   "metadata": {},
   "source": [
    "## Q2. Creating the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c678dd-265b-4edc-96eb-5c9e49a585a0",
   "metadata": {},
   "source": [
    "Now for each document, we will create an embedding for both question and answer fields.\n",
    "\n",
    "We want to put all of them into a single matrix `X`:\n",
    "\n",
    "- Create a list `embeddings` \n",
    "- Iterate over each document \n",
    "- `qa_text = f'{question} {text}'`\n",
    "- compute the embedding for `qa_text`, append to `embeddings`\n",
    "- At the end, let `X = np.array(embeddings)` (`import numpy as np`) \n",
    "\n",
    "What's the shape of X? (`X.shape`). Include the parantheses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "948b2cfb-1cad-4963-9d9a-78799d387075",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for doc in docs_mlzc:\n",
    "    # doc[\"qa_text\"] = f'{docs_mlzc[1][\"question\"]} {docs_mlzc[1][\"text\"]}'\n",
    "    #doc[\"text_vector\"] = embedding_model.encode(doc[\"qa_text\"])\n",
    "    # doc[\"text_vector\"] = embedding_model.encode(f'{docs_mlzc[1][\"question\"]} {docs_mlzc[1][\"text\"]}')\n",
    "    embedding = embedding_model.encode(f'{docs_mlzc[1][\"question\"]} {docs_mlzc[1][\"text\"]}')\n",
    "    embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e455e-5907-489a-b6e0-60fb8fbb64e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62ee6112-e6de-4699-b321-d2cc4255bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af641e04-8896-4356-acf9-05dceb5032d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 768)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2 ANSWER\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de0f552-5b3c-42b7-9602-a830cbb27c25",
   "metadata": {},
   "source": [
    "## Q3. Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b8a8a2-c3b7-4962-bfc8-1eec7460bac4",
   "metadata": {},
   "source": [
    "We have the embeddings and the query vector. Now let's compute the \n",
    "cosine similarity between the vector from Q1 (let's call it `v`) and the matrix from Q2. \n",
    "\n",
    "The vectors returned from the embedding model are already\n",
    "normalized (you can check it by computing a dot product of a vector\n",
    "with itself - it should return something very close to 1.0). This means that in order\n",
    "to compute the coside similarity, it's sufficient to \n",
    "multiply the matrix `X` by the vector `v`:\n",
    "\n",
    "\n",
    "```python\n",
    "scores = X.dot(v)\n",
    "```\n",
    "\n",
    "What's the highest score in the results?\n",
    "\n",
    "- 65.0 \n",
    "- 6.5\n",
    "- 0.65\n",
    "- 0.065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24c47f5e-c85c-4c92-a3b7-40d74c67e55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = encoded\n",
    "scores = X.dot(v)\n",
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ddf51e83-d3ae-4e91-84ca-1e1458c898d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43505073"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER\n",
    "max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1fdd78-4efc-452f-8e04-392a1f781748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
